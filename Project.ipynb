{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f47c7524",
   "metadata": {},
   "source": [
    "![logo_ironhack_blue 7](https://user-images.githubusercontent.com/23629340/40541063-a07a0a8a-601a-11e8-91b5-2f13e4e6b441.png)\n",
    "\n",
    "# PROJECT | Natural Language Processing Challenge\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Learning how to process text is a skill required for Data Scientists/AI Engineers. \n",
    "\n",
    "In this project, you will put these skills into practice to identify whether a news headline is real or fake news.\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "In the file `dataset/data.csv`, you will find a dataset containing news articles with the following columns:\n",
    "\n",
    "- **`label`**: 0 if the news is fake, 1 if the news is real.\n",
    "- **`title`**: The headline of the news article.\n",
    "- **`text`**: The full content of the article.\n",
    "- **`subject`**: The category or topic of the news.\n",
    "- **`date`**: The publication date of the article.\n",
    "\n",
    "Your goal is to build a classifier that is able to distinguish between the two.\n",
    "\n",
    "Once you have a classifier built, then use it to predict the labels for `dataset/validation_data.csv`. Generate a new file\n",
    "where the label `2` has been replaced by `0` (fake) or `1` (real) according to your model. Please respect the original file format, \n",
    "do not include extra columns, and respect the column separator. \n",
    "\n",
    "Please ensure to split the `data.csv` into **training** and **test** datasets before using it for model training or evaluation.\n",
    "\n",
    "## Guidance\n",
    "\n",
    "Like in a real life scenario, you are able to make your own choices and text treatment.\n",
    "Use the techniques you have learned and the common packages to process this data and classify the text.\n",
    "\n",
    "## Deliverables\n",
    "\n",
    "1. **Python Code:** Provide well-documented Python code that conducts the analysis.\n",
    "2. **Predictions:** A csv file in the same format as `validation_data.csv` but with the predicted labels (0 or 1)\n",
    "3. **Accuracy estimation:** Provide the teacher with your estimation of how your model will perform.\n",
    "4. **Presentation:** You will present your model in a 10-minute presentation. Your teacher will provide further instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "33b97894",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can use transformer Model but also need another model\n",
    "# Can check with other models like Logistic Regression, Random Forest, etc.\n",
    "# Can find other training data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e837c9",
   "metadata": {},
   "source": [
    "# Setup the Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "cf024497",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import nltk\n",
    "import re\n",
    "import string\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "831a3964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40399, 5)\n",
      "   label                                              title  \\\n",
      "0      0  HILLARY RODHAM NIXON: A CANDIDATE WITH MORE BA...   \n",
      "1      0  WATCH DIRTY HARRY REID ON HIS LIE ABOUT ROMNEY...   \n",
      "2      0  HILLARY RODHAM NIXON: A CANDIDATE WITH MORE BA...   \n",
      "3      0  FLASHBACK: KING OBAMA COMMUTES SENTENCES OF 22...   \n",
      "4      0  BENGHAZI PANEL CALLS HILLARY TO TESTIFY UNDER ...   \n",
      "\n",
      "                                                text    subject        date  \n",
      "0  The irony here isn t lost on us. Hillary is be...   politics  2015-03-31  \n",
      "1  In case you missed it Sen. Harry Reid (R-NV), ...  left-news  2015-03-31  \n",
      "2  The irony here isn t lost on us. Hillary is be...  left-news  2015-03-31  \n",
      "3  Just making room for Hillary President Obama t...   politics  2015-03-31  \n",
      "4  Does anyone really think Hillary Clinton will ...   politics  2015-03-31  \n"
     ]
    }
   ],
   "source": [
    "## Read Data\n",
    "data = pd.read_csv(\"train_data.csv\",encoding='latin-1')\n",
    "\n",
    "print(data.shape)\n",
    "\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d2e30001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40399, 5)\n"
     ]
    }
   ],
   "source": [
    "# Reduce the training set to speed up development. \n",
    "\n",
    "# data = data.head(1000)\n",
    "\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed5663e",
   "metadata": {},
   "source": [
    "# Text processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3573365c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of        label                                              title  \\\n",
       "0          0  HILLARY RODHAM NIXON: A CANDIDATE WITH MORE BA...   \n",
       "1          0  WATCH DIRTY HARRY REID ON HIS LIE ABOUT ROMNEY...   \n",
       "2          0  HILLARY RODHAM NIXON: A CANDIDATE WITH MORE BA...   \n",
       "3          0  FLASHBACK: KING OBAMA COMMUTES SENTENCES OF 22...   \n",
       "4          0  BENGHAZI PANEL CALLS HILLARY TO TESTIFY UNDER ...   \n",
       "...      ...                                                ...   \n",
       "40394      1  Exclusive: North Korea rules out negotiations ...   \n",
       "40395      1  Freeport evacuating Indonesian mine worker fam...   \n",
       "40396      1  Freeport evacuating Indonesian mine worker fam...   \n",
       "40397      1  Venezuela opposition leader Ledezma flees to S...   \n",
       "40398      1  As Canada prepares for legal pot, ex-cops get ...   \n",
       "\n",
       "                                                    text    subject  \\\n",
       "0      The irony here isn t lost on us. Hillary is be...   politics   \n",
       "1      In case you missed it Sen. Harry Reid (R-NV), ...  left-news   \n",
       "2      The irony here isn t lost on us. Hillary is be...  left-news   \n",
       "3      Just making room for Hillary President Obama t...   politics   \n",
       "4      Does anyone really think Hillary Clinton will ...   politics   \n",
       "...                                                  ...        ...   \n",
       "40394  GENEVA (Reuters) - North Korea on Friday ruled...  worldnews   \n",
       "40395  TIMIKA, Indonesia (Reuters) - U.S. miner Freep...  worldnews   \n",
       "40396  TIMIKA, Indonesia (Reuters) - U.S. miner Freep...  worldnews   \n",
       "40397  CARACAS/BOGOTA (Reuters) - Veteran Venezuelan ...  worldnews   \n",
       "40398  TORONTO (Reuters) - A former Canadian police c...  worldnews   \n",
       "\n",
       "             date  \n",
       "0      2015-03-31  \n",
       "1      2015-03-31  \n",
       "2      2015-03-31  \n",
       "3      2015-03-31  \n",
       "4      2015-03-31  \n",
       "...           ...  \n",
       "40394  2017-11-17  \n",
       "40395  2017-11-17  \n",
       "40396  2017-11-17  \n",
       "40397  2017-11-17  \n",
       "40398  2017-11-17  \n",
       "\n",
       "[40399 rows x 5 columns]>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "3f7ef6af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label                                              title  \\\n",
      "0      0  [HILLARY, RODHAM, NIXON, :, A, CANDIDATE, WITH...   \n",
      "1      0  [WATCH, DIRTY, HARRY, REID, ON, HIS, LIE, ABOU...   \n",
      "2      0  [HILLARY, RODHAM, NIXON, :, A, CANDIDATE, WITH...   \n",
      "3      0  [FLASHBACK, :, KING, OBAMA, COMMUTES, SENTENCE...   \n",
      "4      0  [BENGHAZI, PANEL, CALLS, HILLARY, TO, TESTIFY,...   \n",
      "\n",
      "                                                text    subject        date  \n",
      "0  [The, irony, here, isn, t, lost, on, us, ., Hi...   politics  2015-03-31  \n",
      "1  [In, case, you, missed, it, Sen., Harry, Reid,...  left-news  2015-03-31  \n",
      "2  [The, irony, here, isn, t, lost, on, us, ., Hi...  left-news  2015-03-31  \n",
      "3  [Just, making, room, for, Hillary, President, ...   politics  2015-03-31  \n",
      "4  [Does, anyone, really, think, Hillary, Clinton...   politics  2015-03-31  \n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Tokenize 'title' and 'text' columns and store as new columns\n",
    "data['title'] = data['title'].apply(lambda x: word_tokenize(str(x)))\n",
    "data['text'] = data['text'].apply(lambda x: word_tokenize(str(x)))\n",
    "\n",
    "# Check the result\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "3d7a2605",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = data['title']\n",
    "text = data['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "3e9c32db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>hillary rodham nixon candidate with more bagga...</td>\n",
       "      <td>the irony here isn lost on us hillary is being...</td>\n",
       "      <td>politics</td>\n",
       "      <td>2015-03-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>watch dirty harry reid on his lie about romney...</td>\n",
       "      <td>in case you missed it sen harry reid rnv who a...</td>\n",
       "      <td>left-news</td>\n",
       "      <td>2015-03-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>hillary rodham nixon candidate with more bagga...</td>\n",
       "      <td>the irony here isn lost on us hillary is being...</td>\n",
       "      <td>left-news</td>\n",
       "      <td>2015-03-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>flashback king obama commutes sentences of 22 ...</td>\n",
       "      <td>just making room for hillary president obama t...</td>\n",
       "      <td>politics</td>\n",
       "      <td>2015-03-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>benghazi panel calls hillary to testify under ...</td>\n",
       "      <td>does anyone really think hillary clinton will ...</td>\n",
       "      <td>politics</td>\n",
       "      <td>2015-03-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                              title  \\\n",
       "0      0  hillary rodham nixon candidate with more bagga...   \n",
       "1      0  watch dirty harry reid on his lie about romney...   \n",
       "2      0  hillary rodham nixon candidate with more bagga...   \n",
       "3      0  flashback king obama commutes sentences of 22 ...   \n",
       "4      0  benghazi panel calls hillary to testify under ...   \n",
       "\n",
       "                                                text    subject        date  \n",
       "0  the irony here isn lost on us hillary is being...   politics  2015-03-31  \n",
       "1  in case you missed it sen harry reid rnv who a...  left-news  2015-03-31  \n",
       "2  the irony here isn lost on us hillary is being...  left-news  2015-03-31  \n",
       "3  just making room for hillary president obama t...   politics  2015-03-31  \n",
       "4  does anyone really think hillary clinton will ...   politics  2015-03-31  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_text(text: str) -> str:\n",
    "    # Ensure we are working with a string\n",
    "    text = str(text)\n",
    "\n",
    "    # Remove all special characters (keep only letters, numbers, and spaces)\n",
    "    text = re.sub(r\"[^A-Za-z0-9\\s]\", \"\", text)\n",
    "\n",
    "    # Remove all single characters (like \"a\", \"b\", \"c\" standing alone)\n",
    "    text = re.sub(r\"\\b[A-Za-z]\\b\", \"\", text)\n",
    "\n",
    "    # Remove single characters from the start of the text\n",
    "    text = re.sub(r\"^[A-Za-z]\\s+\", \"\", text)\n",
    "\n",
    "    # Replace multiple spaces with a single space\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "\n",
    "    # Convert everything to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "# clean text\n",
    "data['text'] = data['text'].apply(clean_text)\n",
    "\n",
    "# clean title\n",
    "data['title'] = data['title'].apply(clean_text)\n",
    "\n",
    "data.head() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "65120d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    tokens = word_tokenize(str(text))\n",
    "    filtered = [word for word in tokens if word.lower() not in stop_words and word.isalpha()]\n",
    "    return ' '.join(filtered)\n",
    "\n",
    "# Make a copy to preserve the original data\n",
    "data_nostop = data.copy()\n",
    "\n",
    "# Replace the columns with stopword-removed text\n",
    "data_nostop['title'] = data_nostop['title'].apply(remove_stopwords)\n",
    "data_nostop['text'] = data_nostop['text'].apply(remove_stopwords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "309a47c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>hillary rodham nixon candidate baggage samsoni...</td>\n",
       "      <td>irony lost us hillary compared president wante...</td>\n",
       "      <td>politics</td>\n",
       "      <td>2015-03-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>watch dirty harry reid lie taxes win</td>\n",
       "      <td>case missed sen harry reid rnv announced last ...</td>\n",
       "      <td>left-news</td>\n",
       "      <td>2015-03-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>hillary rodham nixon candidate baggage samsoni...</td>\n",
       "      <td>irony lost us hillary compared president wante...</td>\n",
       "      <td>left-news</td>\n",
       "      <td>2015-03-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>flashback king obama commutes sentences drug d...</td>\n",
       "      <td>making room hillary president obama today anno...</td>\n",
       "      <td>politics</td>\n",
       "      <td>2015-03-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>benghazi panel calls hillary testify oath whit...</td>\n",
       "      <td>anyone really think hillary clinton come clean...</td>\n",
       "      <td>politics</td>\n",
       "      <td>2015-03-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                              title  \\\n",
       "0      0  hillary rodham nixon candidate baggage samsoni...   \n",
       "1      0               watch dirty harry reid lie taxes win   \n",
       "2      0  hillary rodham nixon candidate baggage samsoni...   \n",
       "3      0  flashback king obama commutes sentences drug d...   \n",
       "4      0  benghazi panel calls hillary testify oath whit...   \n",
       "\n",
       "                                                text    subject        date  \n",
       "0  irony lost us hillary compared president wante...   politics  2015-03-31  \n",
       "1  case missed sen harry reid rnv announced last ...  left-news  2015-03-31  \n",
       "2  irony lost us hillary compared president wante...  left-news  2015-03-31  \n",
       "3  making room hillary president obama today anno...   politics  2015-03-31  \n",
       "4  anyone really think hillary clinton come clean...   politics  2015-03-31  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_nostop.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "6da4b03a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>hillary rodham nixon candidate with more bagga...</td>\n",
       "      <td>the irony here isn lost on us hillary is being...</td>\n",
       "      <td>politics</td>\n",
       "      <td>2015-03-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>watch dirty harry reid on his lie about romney...</td>\n",
       "      <td>in case you missed it sen harry reid rnv who a...</td>\n",
       "      <td>left-news</td>\n",
       "      <td>2015-03-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>hillary rodham nixon candidate with more bagga...</td>\n",
       "      <td>the irony here isn lost on us hillary is being...</td>\n",
       "      <td>left-news</td>\n",
       "      <td>2015-03-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>flashback king obama commutes sentences of 22 ...</td>\n",
       "      <td>just making room for hillary president obama t...</td>\n",
       "      <td>politics</td>\n",
       "      <td>2015-03-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>benghazi panel calls hillary to testify under ...</td>\n",
       "      <td>does anyone really think hillary clinton will ...</td>\n",
       "      <td>politics</td>\n",
       "      <td>2015-03-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                              title  \\\n",
       "0      0  hillary rodham nixon candidate with more bagga...   \n",
       "1      0  watch dirty harry reid on his lie about romney...   \n",
       "2      0  hillary rodham nixon candidate with more bagga...   \n",
       "3      0  flashback king obama commutes sentences of 22 ...   \n",
       "4      0  benghazi panel calls hillary to testify under ...   \n",
       "\n",
       "                                                text    subject        date  \n",
       "0  the irony here isn lost on us hillary is being...   politics  2015-03-31  \n",
       "1  in case you missed it sen harry reid rnv who a...  left-news  2015-03-31  \n",
       "2  the irony here isn lost on us hillary is being...  left-news  2015-03-31  \n",
       "3  just making room for hillary president obama t...   politics  2015-03-31  \n",
       "4  does anyone really think hillary clinton will ...   politics  2015-03-31  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842257c7",
   "metadata": {},
   "source": [
    "## Stemming and Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "582f5a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "74d2b16b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>hillary rodham nixon candidate baggage samsoni...</td>\n",
       "      <td>irony lost us hillary compared president wante...</td>\n",
       "      <td>politics</td>\n",
       "      <td>2015-03-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>watch dirty harry reid lie taxes win</td>\n",
       "      <td>case missed sen harry reid rnv announced last ...</td>\n",
       "      <td>left-news</td>\n",
       "      <td>2015-03-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>hillary rodham nixon candidate baggage samsoni...</td>\n",
       "      <td>irony lost us hillary compared president wante...</td>\n",
       "      <td>left-news</td>\n",
       "      <td>2015-03-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>flashback king obama commutes sentences drug d...</td>\n",
       "      <td>making room hillary president obama today anno...</td>\n",
       "      <td>politics</td>\n",
       "      <td>2015-03-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>benghazi panel calls hillary testify oath whit...</td>\n",
       "      <td>anyone really think hillary clinton come clean...</td>\n",
       "      <td>politics</td>\n",
       "      <td>2015-03-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                              title  \\\n",
       "0      0  hillary rodham nixon candidate baggage samsoni...   \n",
       "1      0               watch dirty harry reid lie taxes win   \n",
       "2      0  hillary rodham nixon candidate baggage samsoni...   \n",
       "3      0  flashback king obama commutes sentences drug d...   \n",
       "4      0  benghazi panel calls hillary testify oath whit...   \n",
       "\n",
       "                                                text    subject        date  \n",
       "0  irony lost us hillary compared president wante...   politics  2015-03-31  \n",
       "1  case missed sen harry reid rnv announced last ...  left-news  2015-03-31  \n",
       "2  irony lost us hillary compared president wante...  left-news  2015-03-31  \n",
       "3  making room hillary president obama today anno...   politics  2015-03-31  \n",
       "4  anyone really think hillary clinton come clean...   politics  2015-03-31  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_nostop.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f9177cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_text(text):\n",
    "    tokens = word_tokenize(str(text))\n",
    "    return ' '.join([stemmer.stem(word) for word in tokens])\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    tokens = word_tokenize(str(text))\n",
    "    return ' '.join([lemmatizer.lemmatize(word) for word in tokens])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "ba524df8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>hillari rodham nixon candid baggag samsonit fa...</td>\n",
       "      <td>ironi lost us hillari compar presid want take ...</td>\n",
       "      <td>politics</td>\n",
       "      <td>2015-03-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>watch dirti harri reid lie tax win</td>\n",
       "      <td>case miss sen harri reid rnv announc last week...</td>\n",
       "      <td>left-news</td>\n",
       "      <td>2015-03-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>hillari rodham nixon candid baggag samsonit fa...</td>\n",
       "      <td>ironi lost us hillari compar presid want take ...</td>\n",
       "      <td>left-news</td>\n",
       "      <td>2015-03-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>flashback king obama commut sentenc drug dealer</td>\n",
       "      <td>make room hillari presid obama today announc d...</td>\n",
       "      <td>politics</td>\n",
       "      <td>2015-03-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>benghazi panel call hillari testifi oath white...</td>\n",
       "      <td>anyon realli think hillari clinton come clean ...</td>\n",
       "      <td>politics</td>\n",
       "      <td>2015-03-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                              title  \\\n",
       "0      0  hillari rodham nixon candid baggag samsonit fa...   \n",
       "1      0                 watch dirti harri reid lie tax win   \n",
       "2      0  hillari rodham nixon candid baggag samsonit fa...   \n",
       "3      0    flashback king obama commut sentenc drug dealer   \n",
       "4      0  benghazi panel call hillari testifi oath white...   \n",
       "\n",
       "                                                text    subject        date  \n",
       "0  ironi lost us hillari compar presid want take ...   politics  2015-03-31  \n",
       "1  case miss sen harri reid rnv announc last week...  left-news  2015-03-31  \n",
       "2  ironi lost us hillari compar presid want take ...  left-news  2015-03-31  \n",
       "3  make room hillari presid obama today announc d...   politics  2015-03-31  \n",
       "4  anyon realli think hillari clinton come clean ...   politics  2015-03-31  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stem the data\n",
    "data_norm = data_nostop.copy()\n",
    "\n",
    "data_norm['title'] = data_norm['title'].apply(stem_text)\n",
    "data_norm['text'] = data_norm['text'].apply(stem_text)\n",
    "\n",
    "data_norm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "51c36f06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>hillari rodham nixon candid baggag samsonit fa...</td>\n",
       "      <td>ironi lost u hillari compar presid want take n...</td>\n",
       "      <td>politics</td>\n",
       "      <td>2015-03-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>watch dirti harri reid lie tax win</td>\n",
       "      <td>case miss sen harri reid rnv announc last week...</td>\n",
       "      <td>left-news</td>\n",
       "      <td>2015-03-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>hillari rodham nixon candid baggag samsonit fa...</td>\n",
       "      <td>ironi lost u hillari compar presid want take n...</td>\n",
       "      <td>left-news</td>\n",
       "      <td>2015-03-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>flashback king obama commut sentenc drug dealer</td>\n",
       "      <td>make room hillari presid obama today announc d...</td>\n",
       "      <td>politics</td>\n",
       "      <td>2015-03-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>benghazi panel call hillari testifi oath white...</td>\n",
       "      <td>anyon realli think hillari clinton come clean ...</td>\n",
       "      <td>politics</td>\n",
       "      <td>2015-03-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                              title  \\\n",
       "0      0  hillari rodham nixon candid baggag samsonit fa...   \n",
       "1      0                 watch dirti harri reid lie tax win   \n",
       "2      0  hillari rodham nixon candid baggag samsonit fa...   \n",
       "3      0    flashback king obama commut sentenc drug dealer   \n",
       "4      0  benghazi panel call hillari testifi oath white...   \n",
       "\n",
       "                                                text    subject        date  \n",
       "0  ironi lost u hillari compar presid want take n...   politics  2015-03-31  \n",
       "1  case miss sen harri reid rnv announc last week...  left-news  2015-03-31  \n",
       "2  ironi lost u hillari compar presid want take n...  left-news  2015-03-31  \n",
       "3  make room hillari presid obama today announc d...   politics  2015-03-31  \n",
       "4  anyon realli think hillari clinton come clean ...   politics  2015-03-31  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lemmatize the data\n",
    "data_norm['title'] = data_norm['title'].apply(lemmatize_text)\n",
    "data_norm['text'] = data_norm['text'].apply(lemmatize_text)\n",
    "\n",
    "data_norm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb03d32",
   "metadata": {},
   "source": [
    "# Split the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bde7ea1",
   "metadata": {},
   "source": [
    "TimeSeriesSplit: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.TimeSeriesSplit.html\n",
    "\n",
    "\"With scikit-learn, you can use TimeSeriesSplit for cross-validation on time series data, but for a simple train/test split (as in your code), you should sort by date and split manually (as shown previously).\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "1a808c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (32319, 4)\n",
      "Test set shape: (8080, 4)\n"
     ]
    }
   ],
   "source": [
    "# Ensure 'date' is a datetime column\n",
    "data_norm['date'] = pd.to_datetime(data_norm['date'])\n",
    "\n",
    "# Sort by date\n",
    "data_norm = data_norm.sort_values('date')\n",
    "\n",
    "# Define the split index\n",
    "split_idx = int(len(data_norm) * 0.8)\n",
    "\n",
    "# Split chronologically\n",
    "X = data_norm.drop(['label'], axis=1)\n",
    "y = data_norm['label']\n",
    "\n",
    "X_train = X.iloc[:split_idx]\n",
    "X_test = X.iloc[split_idx:]\n",
    "y_train = y.iloc[:split_idx]\n",
    "y_test = y.iloc[split_idx:]\n",
    "\n",
    "print(\"Training set shape:\", X_train.shape)\n",
    "print(\"Test set shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "45311b72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hillari rodham nixon candid baggag samsonit fa...</td>\n",
       "      <td>ironi lost u hillari compar presid want take n...</td>\n",
       "      <td>politics</td>\n",
       "      <td>2015-03-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>watch dirti harri reid lie tax win</td>\n",
       "      <td>case miss sen harri reid rnv announc last week...</td>\n",
       "      <td>left-news</td>\n",
       "      <td>2015-03-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hillari rodham nixon candid baggag samsonit fa...</td>\n",
       "      <td>ironi lost u hillari compar presid want take n...</td>\n",
       "      <td>left-news</td>\n",
       "      <td>2015-03-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>flashback king obama commut sentenc drug dealer</td>\n",
       "      <td>make room hillari presid obama today announc d...</td>\n",
       "      <td>politics</td>\n",
       "      <td>2015-03-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>benghazi panel call hillari testifi oath white...</td>\n",
       "      <td>anyon realli think hillari clinton come clean ...</td>\n",
       "      <td>politics</td>\n",
       "      <td>2015-03-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  hillari rodham nixon candid baggag samsonit fa...   \n",
       "1                 watch dirti harri reid lie tax win   \n",
       "2  hillari rodham nixon candid baggag samsonit fa...   \n",
       "3    flashback king obama commut sentenc drug dealer   \n",
       "4  benghazi panel call hillari testifi oath white...   \n",
       "\n",
       "                                                text    subject       date  \n",
       "0  ironi lost u hillari compar presid want take n...   politics 2015-03-31  \n",
       "1  case miss sen harri reid rnv announc last week...  left-news 2015-03-31  \n",
       "2  ironi lost u hillari compar presid want take n...  left-news 2015-03-31  \n",
       "3  make room hillari presid obama today announc d...   politics 2015-03-31  \n",
       "4  anyon realli think hillari clinton come clean ...   politics 2015-03-31  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "f7da1ad1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb70067",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f2ba7f",
   "metadata": {},
   "source": [
    "## TF_IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "6eeea32b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text TF-IDF shapes: (32319, 137141) (8080, 137141)\n",
      "Title TF-IDF shapes: (32319, 12157) (8080, 12157)\n",
      "Text TF-IDF feature names: ['aa' 'aaa' 'aaaaackkk' ... 'zzzzaaaacccchhh' 'zzzzzzzz' 'zzzzzzzzzzzzz']\n",
      "First 5 rows of text TF-IDF:\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "Title TF-IDF feature names: ['aa' 'aar' 'aarp' ... 'zuckerberg' 'zuma' 'zurich']\n",
      "First 5 rows of title TF-IDF:\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initialize the vectorizer\n",
    "tfidf_vectorizer_text = TfidfVectorizer()\n",
    "\n",
    "# TF-IDF for 'text'\n",
    "X_train_text_tfidf = tfidf_vectorizer_text.fit_transform(X_train['text'])\n",
    "X_test_text_tfidf = tfidf_vectorizer_text.transform(X_test['text'])\n",
    "\n",
    "# TF-IDF for 'title'\n",
    "tfidf_vectorizer_title = TfidfVectorizer()\n",
    "X_train_title_tfidf = tfidf_vectorizer_title.fit_transform(X_train['title'])\n",
    "X_test_title_tfidf = tfidf_vectorizer_title.transform(X_test['title'])\n",
    "\n",
    "# Print shapes\n",
    "print(\"Text TF-IDF shapes:\", X_train_text_tfidf.shape, X_test_text_tfidf.shape)\n",
    "print(\"Title TF-IDF shapes:\", X_train_title_tfidf.shape, X_test_title_tfidf.shape)  \n",
    "\n",
    "# Print feature names and first few rows for 'text'\n",
    "print(\"Text TF-IDF feature names:\", tfidf_vectorizer_text.get_feature_names_out())\n",
    "print(\"First 5 rows of text TF-IDF:\\n\", X_train_text_tfidf[:5].toarray())\n",
    "\n",
    "# Print feature names and first few rows for 'title'\n",
    "print(\"Title TF-IDF feature names:\", tfidf_vectorizer_title.get_feature_names_out())\n",
    "print(\"First 5 rows of title TF-IDF:\\n\", X_train_title_tfidf[:5].toarray())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d861988",
   "metadata": {},
   "source": [
    "## Bag of Words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd01b86",
   "metadata": {},
   "source": [
    "Maybe used later to compare"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5534fa",
   "metadata": {},
   "source": [
    "# Train the Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc866666",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "57db4582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8535891089108911\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.93      0.67      1302\n",
      "           1       0.98      0.84      0.91      6778\n",
      "\n",
      "    accuracy                           0.85      8080\n",
      "   macro avg       0.76      0.88      0.79      8080\n",
      "weighted avg       0.91      0.85      0.87      8080\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1211   91]\n",
      " [1092 5686]]\n"
     ]
    }
   ],
   "source": [
    "# With title\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train_title_tfidf, y_train)\n",
    "\n",
    "predictions_title = clf.predict(X_test_title_tfidf)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, predictions_title))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, predictions_title))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, predictions_title))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "f2ec513f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9627475247524753\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.99      0.90      1302\n",
      "           1       1.00      0.96      0.98      6778\n",
      "\n",
      "    accuracy                           0.96      8080\n",
      "   macro avg       0.91      0.98      0.94      8080\n",
      "weighted avg       0.97      0.96      0.96      8080\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1293    9]\n",
      " [ 292 6486]]\n"
     ]
    }
   ],
   "source": [
    "# With text\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train_text_tfidf, y_train)\n",
    "\n",
    "predictions_text = clf.predict(X_test_text_tfidf)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, predictions_text))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, predictions_text))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, predictions_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "0bdb9205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9608910891089109\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.99      0.89      1302\n",
      "           1       1.00      0.95      0.98      6778\n",
      "\n",
      "    accuracy                           0.96      8080\n",
      "   macro avg       0.90      0.97      0.93      8080\n",
      "weighted avg       0.97      0.96      0.96      8080\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1292   10]\n",
      " [ 306 6472]]\n"
     ]
    }
   ],
   "source": [
    "# Combined\n",
    "\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "# Combine the TF-IDF features for text and title\n",
    "X_train_combined = hstack([X_train_text_tfidf, X_train_title_tfidf])\n",
    "X_test_combined = hstack([X_test_text_tfidf, X_test_title_tfidf])\n",
    "\n",
    "# Train the classifier on the combined features\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train_combined, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "predictions_combined = clf.predict(X_test_combined)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, predictions_combined))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, predictions_combined))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, predictions_combined))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978e03e8",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "bb67886f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8601485148514851\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.96      0.69      1302\n",
      "           1       0.99      0.84      0.91      6778\n",
      "\n",
      "    accuracy                           0.86      8080\n",
      "   macro avg       0.76      0.90      0.80      8080\n",
      "weighted avg       0.92      0.86      0.87      8080\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1253   49]\n",
      " [1081 5697]]\n"
     ]
    }
   ],
   "source": [
    "# With title\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(X_train_title_tfidf, y_train)\n",
    "\n",
    "predictions_title = clf.predict(X_test_title_tfidf)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, predictions_title))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, predictions_title))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, predictions_title))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "5ef5c818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9709158415841584\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.99      0.92      1302\n",
      "           1       1.00      0.97      0.98      6778\n",
      "\n",
      "    accuracy                           0.97      8080\n",
      "   macro avg       0.93      0.98      0.95      8080\n",
      "weighted avg       0.97      0.97      0.97      8080\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1292   10]\n",
      " [ 225 6553]]\n"
     ]
    }
   ],
   "source": [
    "# With text\n",
    "\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(X_train_text_tfidf, y_train)\n",
    "\n",
    "predictions_text = clf.predict(X_test_text_tfidf)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, predictions_text))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, predictions_text))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, predictions_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d46001e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9804455445544554\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94      1302\n",
      "           1       1.00      0.98      0.99      6778\n",
      "\n",
      "    accuracy                           0.98      8080\n",
      "   macro avg       0.95      0.99      0.97      8080\n",
      "weighted avg       0.98      0.98      0.98      8080\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1293    9]\n",
      " [ 149 6629]]\n"
     ]
    }
   ],
   "source": [
    "# Combined\n",
    "\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "# Combine the TF-IDF features for text and title\n",
    "X_train_combined = hstack([X_train_text_tfidf, X_train_title_tfidf])\n",
    "X_test_combined = hstack([X_test_text_tfidf, X_test_title_tfidf])\n",
    "\n",
    "# Train the classifier on the combined features\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(X_train_combined, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "predictions_combined = clf.predict(X_test_combined)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, predictions_combined))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, predictions_combined))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, predictions_combined))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f476f35",
   "metadata": {},
   "source": [
    "## Transformer Model: DeBERTa v3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "88802a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.55.2-py3-none-any.whl.metadata (41 kB)\n",
      "Collecting torch\n",
      "  Downloading torch-2.8.0-cp313-none-macosx_11_0_arm64.whl.metadata (30 kB)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.13/site-packages (from transformers) (3.17.0)\n",
      "Collecting huggingface-hub<1.0,>=0.34.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.34.4-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/lib/python3.13/site-packages (from transformers) (2.1.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.13/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.13/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/lib/python3.13/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.13/site-packages (from transformers) (2.32.3)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Downloading tokenizers-0.21.4-cp39-abi3-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Downloading safetensors-0.6.2-cp38-abi3-macosx_11_0_arm64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/anaconda3/lib/python3.13/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.12.2)\n",
      "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub<1.0,>=0.34.0->transformers)\n",
      "  Downloading hf_xet-1.1.7-cp37-abi3-macosx_11_0_arm64.whl.metadata (703 bytes)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.13/site-packages (from torch) (72.1.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/anaconda3/lib/python3.13/site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.13/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.13/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.13/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.13/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.13/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.13/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.13/site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.13/site-packages (from requests->transformers) (2025.6.15)\n",
      "Downloading transformers-4.55.2-py3-none-any.whl (11.3 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.34.4-py3-none-any.whl (561 kB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m561.5/561.5 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading hf_xet-1.1.7-cp37-abi3-macosx_11_0_arm64.whl (2.6 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.21.4-cp39-abi3-macosx_11_0_arm64.whl (2.7 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.8.0-cp313-none-macosx_11_0_arm64.whl (73.6 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m73.6/73.6 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.6.2-cp38-abi3-macosx_11_0_arm64.whl (432 kB)\n",
      "Installing collected packages: safetensors, hf-xet, torch, huggingface-hub, tokenizers, transformers\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m6/6\u001b[0m [transformers][0m [transformers]\n",
      "\u001b[1A\u001b[2KSuccessfully installed hf-xet-1.1.7 huggingface-hub-0.34.4 safetensors-0.6.2 tokenizers-0.21.4 torch-2.8.0 transformers-4.55.2\n"
     ]
    }
   ],
   "source": [
    "! pip install transformers torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "fb818b72",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
    "\n",
    "# Choose model: \"microsoft/deberta-v3-base\"\n",
    "model_name = \"microsoft/deberta-v3-base\"\n",
    "\n",
    "# Load tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "\n",
    "# Create pipeline\n",
    "nlp = pipeline(\"text-classification\", model=model, tokenizer=tokenizer, device=0)  # remove device=0 if not using GPU\n",
    "\n",
    "# Example: predict on test set (using 'text' column)\n",
    "preds = [nlp(text, truncation=True)[0]['label'] for text in X_test['text']]\n",
    "\n",
    "# Convert labels if needed (e.g., 'LABEL_0' -> 0, 'LABEL_1' -> 1)\n",
    "preds = [int(label.split('_')[-1]) for label in preds]\n",
    "\n",
    "print(preds[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81df60e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
